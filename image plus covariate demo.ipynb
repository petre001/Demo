{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabbe414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T19:18:39.521490Z",
     "start_time": "2022-06-09T19:18:39.518293Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is a sample notebook that shows the basic premise of how\n",
    "# a model can combine both imaging and covariate features. \n",
    "#\n",
    "# Due to the sample nature, none of the models are trained and a\n",
    "# find prediction cannot be shown and would not be accurate at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67da7730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T19:18:41.353814Z",
     "start_time": "2022-06-09T19:18:39.528070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Do not use a GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c13b62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T19:18:41.368526Z",
     "start_time": "2022-06-09T19:18:41.356113Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build simple data generator\n",
    "\n",
    "# Additional patient features\n",
    "\n",
    "covariate_columns = [\n",
    "    'Age',\n",
    "    'Sex_F', \n",
    "    'Sex_M',\n",
    "    'APOE A1_2', \n",
    "    'APOE A1_3', \n",
    "    'APOE A1_4', \n",
    "    'APOE A2_2',\n",
    "    'APOE A2_3', \n",
    "    'APOE A2_4', \n",
    "    'LEFT_HIPPOCAMPUS_VOLUME',\n",
    "    'RIGHT_HIPPOCAMPUS_VOLUME', \n",
    "    'MMSE Total Score',\n",
    "    'ADAS13',\n",
    "    'AD', \n",
    "    'CN', \n",
    "    'EMCI', \n",
    "    'LMCI', \n",
    "    'MCI',\n",
    "    'SMC'\n",
    "]\n",
    "\n",
    "class DataGenerator_Gaussian_Labels(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(\n",
    "        self, \n",
    "        target, \n",
    "        batch_size, \n",
    "        dim,\n",
    "        shuffle\n",
    "    ):\n",
    "        \n",
    "        # Get data dir and subject ids\n",
    "        self.data_dir = Path('data/matched_images/{}/mri_final/{}_input_{}x{}x{}_trimmed'.format(\n",
    "            target, target, dim[0], dim[1], dim[2]\n",
    "        ))\n",
    "        self.subject_ids = [int(x.split('.npy')[0]) for x in os.listdir(self.data_dir) if '.npy' in x]\n",
    "        \n",
    "        # Get labels and covariates\n",
    "        label_df = pd.read_csv('csv/generated/{}_complete_updated_gaussian.csv'.format(target))\n",
    "        self.covariates = label_df[covariate_columns].T.to_dict('list')\n",
    "        self.labels = label_df['A_GAUSSIAN_CLS'].to_dict()\n",
    "    \n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.subject_ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        temp_subject_ids = [self.subject_ids[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(temp_subject_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.subject_ids))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, temp_subject_ids):\n",
    "        # Initialization\n",
    "        X_imgs = np.empty((self.batch_size, *self.dim))\n",
    "        X_covariates = np.empty((self.batch_size, len(covariate_columns)), dtype=float)\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(temp_subject_ids):\n",
    "            img = np.load(self.data_dir / '{:04d}.npy'.format(ID))\n",
    "            \n",
    "            # Store sample\n",
    "            X_imgs[i,] = img\n",
    "            X_covariates[i] = self.covariates[ID]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return (X_imgs, X_covariates), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98572f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T19:18:41.512162Z",
     "start_time": "2022-06-09T19:18:41.370688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create generator\n",
    "\n",
    "train_gen = DataGenerator_Gaussian_Labels(\n",
    "    target = 'A_train', \n",
    "    batch_size = 1, \n",
    "    dim = [182, 182, 218], \n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba64f80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T19:18:41.523802Z",
     "start_time": "2022-06-09T19:18:41.514618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a model that returns features generated from image\n",
    "\n",
    "def Image_Feature_Generator(width=182, height=182, depth=218, dropout=0.5, image_features=50):\n",
    "    image_input = layers.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=8, kernel_size=3, padding=\"same\")(image_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters=16, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=32, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(1300, activation='relu')(x)\n",
    "    outputs = layers.Dense(image_features, activation='relu')(x)\n",
    "    \n",
    "    # Define the model.\n",
    "    model = keras.Model(image_input, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1ac73cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T19:18:41.757546Z",
     "start_time": "2022-06-09T19:18:41.525580Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "network = Image_Feature_Generator(\n",
    "    dropout = 0.5, \n",
    "    image_features = 50\n",
    ") \n",
    "network.compile(\n",
    "    optimizer = Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.binary_crossentropy, \n",
    "    metrics=['binary_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987b98b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T19:18:42.175250Z",
     "start_time": "2022-06-09T19:18:41.759218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
       "array([0.19271973, 0.10543033, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.10589558, 0.        , 0.18437165, 0.38739026,\n",
       "       0.        , 0.15440817, 0.        , 0.        , 0.        ,\n",
       "       0.06293368, 0.        , 0.09729211, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.12967616, 0.13662846, 0.14129728, 0.        , 0.        ,\n",
       "       0.07223156, 0.        , 0.        , 0.        , 0.11627224,\n",
       "       0.        , 0.0899682 , 0.01199139, 0.        , 0.08200311,\n",
       "       0.075515  , 0.        , 0.02645394, 0.15401304, 0.        ,\n",
       "       0.        , 0.        , 0.02565606, 0.        , 0.09327351])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get sample image features\n",
    "\n",
    "for x, y in train_gen:\n",
    "    x_images, x_covariates = x\n",
    "    \n",
    "    image_features = network(x_images)\n",
    "    \n",
    "    break\n",
    "  \n",
    "image_features = tf.cast(tf.squeeze(image_features), tf.float64)\n",
    "\n",
    "image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c0ef745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T19:18:42.180273Z",
     "start_time": "2022-06-09T19:18:42.176782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(19,), dtype=float64, numpy=\n",
       "array([0.38235294, 1.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.3664525 ,\n",
       "       0.39123905, 0.91304348, 0.32394366, 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the covariate features\n",
    "x_covariates = tf.squeeze(x_covariates)\n",
    "\n",
    "x_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd8d2d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T19:18:42.187256Z",
     "start_time": "2022-06-09T19:18:42.182346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(69,), dtype=float64, numpy=\n",
       "array([0.19271973, 0.10543033, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.10589558, 0.        , 0.18437165, 0.38739026,\n",
       "       0.        , 0.15440817, 0.        , 0.        , 0.        ,\n",
       "       0.06293368, 0.        , 0.09729211, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.12967616, 0.13662846, 0.14129728, 0.        , 0.        ,\n",
       "       0.07223156, 0.        , 0.        , 0.        , 0.11627224,\n",
       "       0.        , 0.0899682 , 0.01199139, 0.        , 0.08200311,\n",
       "       0.075515  , 0.        , 0.02645394, 0.15401304, 0.        ,\n",
       "       0.        , 0.        , 0.02565606, 0.        , 0.09327351,\n",
       "       0.38235294, 1.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.3664525 ,\n",
       "       0.39123905, 0.91304348, 0.32394366, 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now take those image features and add them to the covariate data\n",
    "\n",
    "image_plus_covariate_input = tf.concat([image_features, x_covariates], axis=0)\n",
    "\n",
    "image_plus_covariate_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b4554b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T19:18:42.413653Z",
     "start_time": "2022-06-09T19:18:42.189422Z"
    }
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-658bd9f9eee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_plus_covariate_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Show prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mclass\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \"\"\"\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Feed all of this data through a simple logistic regression model\n",
    "\n",
    "# Define model\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Predict\n",
    "pred = classifier.predict(image_plus_covariate_input)\n",
    "\n",
    "# Show prediction\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
