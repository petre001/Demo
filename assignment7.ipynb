{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "assignment7.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/petre001/Demo/blob/main/assignment7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmodRgbX_FrG"
      },
      "source": [
        "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqEMTV0S_FrM"
      },
      "source": [
        "NAME = \"Jeffrey Petrella\"\n",
        "COLLABORATORS = \"None\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25zEN_eQ_FrQ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cc84b7a93b06344ffabe0cd04b7c07d5",
          "grade": false,
          "grade_id": "cell-191cb99e070271d7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "S6eO5hcn_FrT"
      },
      "source": [
        "<a href='https://ai.meng.duke.edu'> = <img align=\"left\" style=\"padding-top:10px;\" src=https://storage.googleapis.com/aipi_datasets/Duke-AIPI-Logo.png>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "91652413df725955836a9fb576908cc8",
          "grade": false,
          "grade_id": "cell-cdb80ac81ceafe86",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "lhfrKPpU_FrU"
      },
      "source": [
        "# Assignment 7: Sensor selection for a wearable stress detector product\n",
        "<img align=\"left\" style=\"padding-top:10px;\" src=\"https://github.com/AIPI510/assignment7-petre001/blob/master/Respiban.png?raw=1\">  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "71ab277f52dc0dfd4957744585ee8bc6",
          "grade": false,
          "grade_id": "cell-e12547c7ef6c4758",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pbdB51hF_FrV"
      },
      "source": [
        "## Background\n",
        "Long-term stress has been proven to have harmful health effects, ranging from headaches, sleeping difficulties, and even increased risk for cardiovascular diseases.  For an individual, the ability to automatically detect signs of ongoing stress can help them to seek intervention to reduce stress levels, resulting in a reduction in harmful side-effects. \n",
        "\n",
        "The scenario for our project is that we are working for a company interested in developing a wearable chest-strap stress detection device, which uses sensors to detect physiological signs of stress and then alerts the user so they can take proactive action to reduce stress in order to mitigate potential long-term health effects.  The objective for our project is to determine which sensors need to be included on the new wearable device in order to accurately detect stress.\n",
        "\n",
        "From our interviews of domain experts, we learn that stress is a physiological response to stimulus triggered by the sympathetic nervous system.  During this response, hormones are released that lead to physiological changes such as increased respiratory rate, increased heart rate, muscle tension, and increased motion.  In order to build our model, we develop a list of possible physiological and motion signals which can be feasibly measured by sensors on a non-invasive wearable device:  \n",
        "- Motion/acceleration\n",
        "- Electrocardiography\n",
        "- Electrodermal activity\n",
        "- Electromyography\n",
        "- Respiration\n",
        "- Skin temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2ec24b0fe7a2a255d2d7c0bb86eb6a22",
          "grade": false,
          "grade_id": "cell-04229c389fe2efcf",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZumAsE3D_FrZ"
      },
      "source": [
        "## Data\n",
        "\n",
        "To assist in our project, we will use data which is adapted (modified for purposes of this exercise) from the Wearable Stress and Affect Detection (WESAD) study done by engineers at Bosch which includes high-resolution data from several sensors together with labels of the subject's mood at each point in time over the duration of the study period.  The sensors are contained on two devices - one chest-based and the other wrist-based.  The description of the data in the study is below.  The study contains data on several participants - we will use the data for just one individual (S2) from the RespiBAN chest sensor array.\n",
        "\n",
        "**Description of the dataset:**  \n",
        "The study authors used the RespiBAN chest sensor to measure physiological signals and motion: http://www.biosignalsplux.com/en/respiban-professional. All signals were sampled at 700 Hz. Raw data is contained in SX_respiban.txt (where 'X' represents the patient number, e.g. 'S2_respiban.txt' for patient #2.). There are 10 columns here. First column: sequential line number. Second column: ignore. Columns 3-10: raw data of the 8 sensor channels. The order of the channels is defined in the header. The entries “XYZ” refer to the 3-channel accelerometer (thus, acceleration data is provided in 3 columns). In order to convert the raw sensor values into SI units, each signal has to be transformed based on the formulas given below ('signal' contains the raw sensor values, vcc=3, chan_bit=2^16).\n",
        "- ECG (mV): `(signal/chan_bit-0.5)*vcc` Details: http://www.biosignalsplux.com/datasheets/ECG_Sensor_Datasheet.pdf\n",
        "- EDA (μS): `((signal/chan_bit)*vcc)/0.12` Details: http://www.biosignalsplux.com/datasheets/EDA_Sensor_Datasheet.pdf\n",
        "- EMG (mV): `(signal/chan_bit-0.5)*vcc` Details: http://www.biosignalsplux.com/datasheets/EMG_Sensor_Datasheet.pdf\n",
        "- TEMP (°C):  \n",
        "    vout = `signal*vcc/chan_bit`  \n",
        "    rntc = `((10^4)*vout)/(vcc-vout)`  \n",
        "    TEMP = `- 273.15 + 1./(1.12764514*10^(-3) + 2.34282709*10^(-4)*log(rntc) + 8.77303013*10^(-8)*(log(rntc))^3)`  \n",
        "    Details: http://www.biosignalsplux.com/datasheets/TMP_Sensor_Datasheet.pdf\n",
        "- XYZ (g): `(signal-Cmin)/(Cmax-Cmin)*2 - 1`, where Cmin = 28000 and Cmax = 38000  \n",
        "Details: http://www.biosignalsplux.com/datasheets/ACC_Sensor_Datasheet.pdf\n",
        "- RESPIRATION (%): `(signal/chan_bit - 0.5) * 100` Details: http://www.biosignalsplux.com/datasheets/PZT_Sensor_Datasheet.pdf\n",
        "\n",
        "**Reference publication:**  \n",
        "Philip Schmidt, Attila Reiss, Robert Duerichen, Claus Marberger and Kristof Van Laerhoven. 2018. Introducing WESAD, a multimodal dataset for Wearable Stress and Affect Detection. In 2018 International Conference on Multimodal Interaction (ICMI ’18), October 16–20, 2018, Boulder, CO, USA. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3242969.3242985\n",
        "\n",
        "Originial (unadjusted) dataset can be found at https://ubicomp.eti.uni-siegen.de/home/datasets/icmi18/. The dataset used in this exercise has been adapted from the original to facilitate the learning objectives of this exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "719d25f0189865d8fb8ee984313fcd47",
          "grade": false,
          "grade_id": "cell-443cc48de5e91f17",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "99XK-Udt_Frj"
      },
      "source": [
        "# Run this before any other code cell\n",
        "# This downloads the csv data files into the same directory where you have saved this notebook\n",
        "\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "import os\n",
        "path = Path()\n",
        "\n",
        "# Dictionary of file names and download links\n",
        "files = {'S2_respiban_adjusted.txt':'https://storage.googleapis.com/aipi_datasets/S2_respiban_adjusted.txt',\n",
        "        'S2_labels.csv':'https://storage.googleapis.com/aipi_datasets/S2_labels.csv'}\n",
        "\n",
        "# Download each file\n",
        "for key,value in files.items():\n",
        "    filename = path/key\n",
        "    url = value\n",
        "    # If the file does not already exist in the directory, download it\n",
        "    if not os.path.exists(filename):\n",
        "        urllib.request.urlretrieve(url,filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cf3f486d64e4de36d38c920719cf230a",
          "grade": false,
          "grade_id": "cell-66c42142f35d7616",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "RRWdf9Mw_Fro"
      },
      "source": [
        "# Import needed libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "889b1beb078c165981d6eb1130f1c474",
          "grade": false,
          "grade_id": "cell-43f7e0a34185891d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "P3NwCEEM_Frw"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4f293f67b8717c6ff71167526e074152",
          "grade": false,
          "grade_id": "cell-7368c18a5ac3ef8a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3Xk5fkC7_Fry"
      },
      "source": [
        "# Read in the raw data from the txt file\n",
        "raw_data = pd.read_csv('S2_respiban_adjusted.txt',sep = '\\t',skiprows=3,header=None,)\n",
        "\n",
        "chest_data = raw_data.copy() # Work with a copy to preserve the raw dataframe\n",
        "\n",
        "# We can delete columns 0,1,10 per the data description\n",
        "chest_data = chest_data.iloc[:,2:10]\n",
        "chest_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "50594af3334be161909250f10869267d",
          "grade": false,
          "grade_id": "cell-6388cbf159199639",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XcuvUrEI_Fr0"
      },
      "source": [
        "# Read in the metadata\n",
        "with open('S2_respiban_adjusted.txt') as f:\n",
        "    lines = f.readlines()\n",
        "metadata = lines[1]\n",
        "metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8c4e251d38965a93b99f474482400f9a",
          "grade": false,
          "grade_id": "cell-d21f0c6688ac7400",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JF-riMPa_Fr2"
      },
      "source": [
        "### Question 1\n",
        "Complete the below function `create_df()` which takes the raw data dataframe (`chest_data`) and the metadata string (`metadata`) as input and performs the following:  \n",
        "- Adds the column names to the dataframe (`chest_data`).  The column names can be extracted from the metadata - they are contained in a list with the key \"sensor\" in the metadata dictionary (e.g. \"ECG\",\"EDA\" etc).  Please extract them using Python, rather than manually typing them in, and ensure you remove all punctuation and white space from them, including quotation signs around them.  \n",
        "- Convert the dataframe index to a timedelta index with the units as seconds.  As per the data description above, the chest sensor and label data is sampled at 700 Hz\n",
        "\n",
        "Your function should return the dataframe with the above two changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "34ffa71acf52b746fa372be64341edca",
          "grade": false,
          "grade_id": "cell-88ae1b4c30798e7c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "IOoPaKZ-_Fr3"
      },
      "source": [
        "def create_df(raw_data,meta_data):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ab1b401eab0bac82e5667bc257c333f3",
          "grade": true,
          "grade_id": "cell-3f3f874dac6be99b",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "LzKpSfSE_Fr5"
      },
      "source": [
        "df = create_df(chest_data.copy(),metadata)\n",
        "assert set(df.columns) == set(['ECG', 'EDA', 'EMG', 'TEMP', 'XYZ1', 'XYZ2', 'XYZ3', 'RESPIRATION'])\n",
        "assert np.round(np.max(df.index.total_seconds())/60,1)==105.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "acdfe1c1d6dd080a1ea0fd44c4cc1cb2",
          "grade": false,
          "grade_id": "cell-fb88b00f7aeca8ca",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "hzvAC3_4_Fr6"
      },
      "source": [
        "Let's now read in our mood label data.  Run the cell below to read in the labels and organize them in a dictionary.  The dictionary contains the start and end time in minutes for each label (labels are contained in order as a list with the key 'ORDER')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "48e49c7de88d3a30bae7f72e9cac0948",
          "grade": false,
          "grade_id": "cell-3f4f97c6e99caaf7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7iFcQYZx_Fr7"
      },
      "source": [
        "# Read in the labels csv to a dictionary containing label and start and end time for each\n",
        "labels = {}\n",
        "with open('S2_labels.csv') as f:\n",
        "    lines = f.readlines()\n",
        "for line in lines[1:]:\n",
        "    key = line.split(';')[0].strip('# ')\n",
        "    values = [line.strip() for line in line.split(';')[1:]]\n",
        "    labels[key] = values\n",
        "# Convert start and end times to float\n",
        "labels['START'] = [float(x) for x in labels['START']]\n",
        "labels['END'] = [float(x) for x in labels['END']]\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fde64973b400ed431776a62197ccabe4",
          "grade": false,
          "grade_id": "cell-382bd44c8d5e7fa8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MI9IcRLQ_Fr7"
      },
      "source": [
        "### Question 2\n",
        "Complete the below function `add_labels()` which takes the dataframe output from your `create_df()` function and the dictionary containing the labels (`labels`) as inputs.  The function should add a new column to your dataframe named 'label' which contains the corresponding mood label for each point in time.  After you have added the labels, filter your dataframe to remove any observations where there is no label.  Your function should return the dataframe with the above changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d0e8ba1c410ab2770f960debac9f7943",
          "grade": false,
          "grade_id": "cell-4df67ccf2e507d6d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "fqNSU9SJ_Fr8"
      },
      "source": [
        "def add_labels(df,label_dict): \n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "997dcea2cbad5d6b7c07f43407da7ed6",
          "grade": true,
          "grade_id": "cell-36d8669e4cd8ed2e",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "01Kisqjq_Fr9"
      },
      "source": [
        "# Test cell for add_labels()\n",
        "df_wlabels = add_labels(df.copy(),labels)\n",
        "assert 'label' in list(df_wlabels.columns)\n",
        "assert df_wlabels.shape==(1829945, 9)\n",
        "df_wlabels.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fc13dc575a22ed1f653d769c06ac30f2",
          "grade": false,
          "grade_id": "cell-19a3c3bfca4baaad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6YP6Pawx_FsA"
      },
      "source": [
        "## Clean up data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2a68e2930586d504460ab45e69519a8a",
          "grade": false,
          "grade_id": "cell-6b5f0cbe2bc991d4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XRJx2XQa_FsA"
      },
      "source": [
        "### Question 3\n",
        "Complete the below function `unitize()` which takes as input the dataframe output from your `add_labels()` function and values for vcc, chan_bit, Cmax, Cmin (see sensor datasheet links above for details).  The function should do the following:  \n",
        "- Use the transfer function equations given in the sensor spec sheets (and the description above in the Data section) to convert the raw values into the proper units for ALL sensors in the input dataframe.  As an example, the calculation for temperature conversion is provided.  \n",
        "- After converting to units, combine the three components of acceleration to get one acceleration factor with the total magnitude of acceleration (take the square root of the sum of squared components of acceleration).\n",
        "\n",
        "Your function should return a dataframe which contains the following columns: ['ECG','EDA','EMG','TEMP','RESPIRATION','ACC','label'] (the order of columns does not matter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "735def388aef7d0528f354bb68c21f55",
          "grade": false,
          "grade_id": "cell-5613497ff5642e8f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "gF-M3hLx_FsB"
      },
      "source": [
        "def unitize(df, vcc, chan_bit, Cmax, Cmin):\n",
        "    df_units = df.copy()\n",
        "        \n",
        "    # Temp calculation as an example\n",
        "    vout = df['TEMP']*vcc/(chan_bit)\n",
        "    rntc = 10**4*vout/(vcc-vout)\n",
        "    df_units['TEMP'] = -273.15 + 1./(1.12764514*(10**(-3)) + 2.34282709*10**(-4)*np.log(rntc) + 8.77303013*10**(-8)*(np.log(rntc))**3)\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2b9f0b8116779b7702dd0d5bad049196",
          "grade": true,
          "grade_id": "cell-b76fff3eb3c6996d",
          "locked": true,
          "points": 15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "s3ztTj3K_FsD"
      },
      "source": [
        "# Test cell for unitize()\n",
        "vcc = 3\n",
        "chan_bit = 2**16\n",
        "Cmax = 38000\n",
        "Cmin = 28000\n",
        "df_units = unitize(df_wlabels.copy(),vcc,chan_bit,Cmax,Cmin)\n",
        "\n",
        "assert set(df_units.columns) == set(['ECG','EDA','EMG','TEMP','RESPIRATION','ACC','label'])\n",
        "assert df_units.iloc[0,:].loc['label']=='Baseline'\n",
        "assert np.round(df_units.iloc[0,:].loc['ACC'],2)==0.93\n",
        "\n",
        "display(df_units.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "96b1aeddd65b6830359324e2c2650883",
          "grade": false,
          "grade_id": "cell-bbd723e6d8e4ce17",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ahcs2OUA_FsE"
      },
      "source": [
        "\n",
        "### Question 4\n",
        "Complete the below function `clean_data()` which takes as input the dataframe output from your `unitize()` function and a list of labels to filter on (`relevant_labels`).  The function should perform the following:  \n",
        "- Filter the dataframe to only contain rows with a label included in `relevant_labels`  \n",
        "- Then, fill the null signal values in the filtered dataframe using a forward-fill approach (set them equal to the last observed value in time before the null value)  \n",
        "\n",
        "Your function should return the cleaned dataframe with rows corresponding only to the mood labels in `relevant_labels` and no null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cbf8d9012e42a63236dfbcd77a278d69",
          "grade": false,
          "grade_id": "cell-5499a9e7256c641b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "viaficd__FsE"
      },
      "source": [
        "def clean_data(df, relevant_labels):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d966bb4e5399e38f77d249a965f59703",
          "grade": true,
          "grade_id": "cell-73d77b2959ff73a4",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "nEZrzjUG_FsE"
      },
      "source": [
        "relevant_labels=['Baseline','Stressed','Amusement']\n",
        "chest_data_clean = clean_data(df_units.copy(),relevant_labels)\n",
        "assert set(chest_data_clean['label'].unique())==set(relevant_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6bad5f0d0ac31a24c7d02c7565e6cc4b",
          "grade": false,
          "grade_id": "cell-1db588a57a26c886",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Kp637T99_FsE"
      },
      "source": [
        "## Handle outliers\n",
        "A good place to start in looking for anomalous values is by visually evaluating the data. Let's do this by creating a simple plot of each signal over the period, and observe whether we see unusual values.  Warning: we have a lot of data so these plots may take some time to generate.  If it gets stuck, don't worry about running this cell, it's not needed to answer the questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f09419602816c6aae4ebdaf88ee914af",
          "grade": false,
          "grade_id": "cell-2922ffd6e3643041",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DKSsxWEu_FsG"
      },
      "source": [
        "# Look at plots of the raw data over the study period (this may take some time to run)\n",
        "# Set up grid\n",
        "fig,ax = plt.subplots(2,3,figsize=(20,10))\n",
        "# Make lineplots for each signal\n",
        "for i,sig in enumerate(['ECG','EDA','EMG','TEMP','RESPIRATION','ACC']):\n",
        "    axis=ax[i//3,i%3]\n",
        "    axis.scatter(x=chest_data_clean.index.total_seconds(), y=chest_data_clean[sig],s=2)\n",
        "    axis.set_title(sig)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b28ba850a77e299829d2aeb1f19b328d",
          "grade": false,
          "grade_id": "cell-ebf8d28b528985a6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zpf8FcEs_FsG"
      },
      "source": [
        "### Question 5\n",
        "Let's now look at a couple of statistical methods of determining if these points are outliers and likely to be anomalous.  Let's start by using the Standard Deviation method.  This method assumes that the distribution of the data is Gaussian or Gaussian-like.  We calculate the mean and standard deviation of the data, and then identify any point which falls above an upper limit or below a lower limit which are calculated as +/- k standard deviations from the mean.  A value of k=3 standard deviations is commonly used, although for large sample sizes a higher value may be used.  In this case, since we have a large number of datapoints and our goal is solely to filter out values which are almost certainly anomalous we will use a large value for k. \n",
        "\n",
        "Complete the below function `detect_anomalies_stdev()` which takes as input a pandas series (one column of your `chest_data_clean` dataframe at a time) and a value of k, and returns a **list** of the timedelta index values of the outlier points for that feature.  For example, if we provide as input the 'ECG' column, the function should return the timedelta index values of potential outlier points based on ECG values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8f7f1796cd0d56ac24aa97b22e6b01b8",
          "grade": false,
          "grade_id": "cell-16988d5cfc19ffc7",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "drWMICfB_FsG"
      },
      "source": [
        "# Function to detect outliers from a pandas series using the standard deviation approach\n",
        "def detect_anomalies_stdev(col, k):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "467f9349026a251fbac79bda4f45999a",
          "grade": true,
          "grade_id": "cell-a88e1d5b13aca113",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "uIOEHgeO_FsG"
      },
      "source": [
        "# Compute and print the potential anomalous rows for each signal\n",
        "all_anomalies_std = []\n",
        "k = 15\n",
        "for sig in ['ECG','EDA','EMG','TEMP','RESPIRATION','ACC']:\n",
        "    anomalies_std = detect_anomalies_stdev(chest_data_clean[sig],k)\n",
        "    all_anomalies_std += anomalies_std\n",
        "\n",
        "# Print the set of all possible anomalous rows\n",
        "all_anomalies_std = set(all_anomalies_std)\n",
        "all_anomalies_std = sorted(all_anomalies_std)\n",
        "assert len(set(all_anomalies_std))==11\n",
        "assert all_anomalies_std[0].seconds==463\n",
        "\n",
        "print('\\nThe list of possible anomalous datapoints your function identified is:')\n",
        "print(all_anomalies_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b1c8c0362e1d22fa5dd5cfe8b6e55268",
          "grade": false,
          "grade_id": "cell-f705b903fb4641a8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "FAwYb2eM_FsH"
      },
      "source": [
        "### Question 6\n",
        "The above Standard Deviation Method assumes the dataset is Gaussian-like. To determine whether it is an acceptable approach to identifying outliers for our dataset, let's test the data for normality.  One way to do this is a visual test using a Q-Q plot.  In a Q-Q plot, we generate an ideal Gaussian distribution, and each data point in our sample is paired with a similar member from the idealized distribution at the same cumulative distribution. The results are plotted with the idealized distribution on the x-axis and the actual distribution on the y-axis. A perfect match to a Gaussian distribution would be a line of points at a 45-degree angle from the bottom left. Deviance from this line indicates the Gaussian assumption may not fit the data.\n",
        "\n",
        "Complete the below function `test_normality()` which generates Q-Q plots for each signal (['ECG','EDA','EMG','TEMP','RESPIRATION','ACC']).  Run your function, analyze your plots, and then determine if the data for all signals is Gaussian-like based on visual analysis of the plots (you do not need to do any statistical tests to answer this question).  If all data appears Gaussian-like, return the boolean `True` (hard-code as `return True`).  If data for one or more signals does not appear Gaussian-like, return `False`.\n",
        "\n",
        "Note that because we have a large number of datapoints, this may take a bit of time to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e440b6c0c6c2aecde8b1b6f58d054e91",
          "grade": false,
          "grade_id": "cell-dafed844b03e3a66",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "1oWwfVDQ_FsH"
      },
      "source": [
        "def test_normality(chest_data_clean):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d9af9d135bc78f1b8b20f40b208f0ab6",
          "grade": true,
          "grade_id": "cell-384c584dcb2e45fc",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zsTn9nds_FsH"
      },
      "source": [
        "# Test cell for test_normality()\n",
        "normal = test_normality(chest_data_clean)\n",
        "assert type(normal)==bool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a8d0c6bdde486f298fab155199fb6a02",
          "grade": false,
          "grade_id": "cell-291bf8d748418091",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qdm-ebKZ_FsI"
      },
      "source": [
        "### Question 7\n",
        "Alternatively, we can detect possible anomalies using the Interquartile Range (IQR) Method.  The IQR method is often used for detecting outliers in non-Gaussian data.  The IQR is calculated as the difference between the 75th percentile and the 25th percentile in the data.  Upper and lower thresholds are typically set as `k * IQR` above and below the 75% and 25th percentiles, respectively.  Any data point that falls above the upper threshold or below the lower threshold is deemed a possible outlier.  A value of 1.5 is commonly used for k\n",
        "\n",
        "Complete the below function `detect_anomalies_iqr()` which takes as input a pandas series (one column of your `chest_data_clean` dataframe at a time) and a value k (see above), computes the IQR and the upper and lower thresholds, and then outputs a list of the timedelta index values of any rows which are above or below the upper or lower threshold for the signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f8003f1acaea095a69621574f108e93f",
          "grade": false,
          "grade_id": "cell-e07b9adbdda8abf6",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "raPvvB8K_FsJ"
      },
      "source": [
        "def detect_anomalies_iqr(col,k):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "16da95958cf042729d6dd616172ef2ce",
          "grade": true,
          "grade_id": "cell-c50dbc69d8fc9b0c",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "TS8DqUS-_FsJ"
      },
      "source": [
        "# Test cell for detect_anomalies_iqr()\n",
        "all_anomalies_iqr = []\n",
        "k=15 # We use a large k since the data has high variance and we are looking for extreme outliers only\n",
        "for sig in ['ECG','EDA','EMG','TEMP','RESPIRATION','ACC']:\n",
        "    anomalies_iqr = detect_anomalies_iqr(chest_data_clean[sig],k)\n",
        "    all_anomalies_iqr += anomalies_iqr\n",
        "\n",
        "# Print the set of all possible anomalous rows\n",
        "all_anomalies_iqr = set(all_anomalies_iqr)\n",
        "all_anomalies_iqr = sorted(all_anomalies_iqr)\n",
        "assert len(all_anomalies_iqr)==11\n",
        "assert all_anomalies_iqr[0].seconds == 463\n",
        "print(f'\\nThe list of all possible anomalous datapoints is:')\n",
        "print(all_anomalies_iqr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1c660e22487f379975b0d61aacec0cce",
          "grade": false,
          "grade_id": "cell-25ce80a3d0f425fa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3rpztu9U_FsJ"
      },
      "source": [
        "### Question 8\n",
        "Let's now remove the anomalous rows from our dataset which were detected using the IQR method.  Complete the function below `remove_IQR_outliers()` which returns the input dataframe with the rows containing the identified outlier values (in any column, using the IQR method) removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3ba678e055e79b4a6c7da287c20983c3",
          "grade": false,
          "grade_id": "cell-7a939f62232cb18d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "a6GWGUaT_FsJ"
      },
      "source": [
        "def remove_IQR_outliers(df):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "aab449e36179e66372ca387f2af82d8a",
          "grade": true,
          "grade_id": "cell-621780cf4f921487",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "5u1kLile_FsJ"
      },
      "source": [
        "# Test cell for remove_IQR_outliers()\n",
        "chest_data_no_outliers = remove_IQR_outliers(chest_data_clean.copy())\n",
        "rows_removed = chest_data_clean.shape[0] - chest_data_no_outliers.shape[0]\n",
        "print('Your function removed {} rows'.format(rows_removed))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8d149bfe079d08600720d524caa3e94d",
          "grade": false,
          "grade_id": "cell-efb9cf65f61ee0af",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "QIr61MuQ_FsJ"
      },
      "source": [
        "## Analyze the data\n",
        "\n",
        "Our data is now in proper units, filtered for modeling, and scrubbed to remove null values and anomalies.  Now we are ready to explore the data to identify trends and patterns which we can use to determine which sensors help us most in identifying periods of stress."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "42d8f52910099ff77e917e2024f86533",
          "grade": false,
          "grade_id": "cell-5af09af702137ecc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "hLKcLJte_FsJ"
      },
      "source": [
        "### Question 9\n",
        "Complete the below function `signals_boxplot()`.  The function should create a boxplot of the values for each signal, so you should have 6 boxplots in total - one each for ['ECG','EDA','EMG','TEMP','RESPIRATION','ACC'].  You should group the data for each boxplot by the mood label ('Amusement','Baseline','Stressed').  \n",
        "\n",
        "Take a look at the boxplots you have created for 'TEMP' and 'EDA'.  For each of those signals, determine visually from your boxplot (no need to calculate it) whether the median value for the 'Stressed' datapoints is higher than the median value for the 'Baseline' points.  If it is, return the boolean `True` for the signal, otherwise return `False`.  The output from your function should be two boolean values indicating whether the median of the signal is higher for the 'Stressed' datapoints relative to the baseline for 1) 'Temp' and 2) 'EDA'.  For example, if the median for both is higher, your function would return `return True, True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "43e3c900bbeeebab95f46062b0b7f717",
          "grade": false,
          "grade_id": "cell-080928735d09daca",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "X229XuHC_FsJ"
      },
      "source": [
        "def signals_boxplot(df):\n",
        "    # Plot box plots for each sensor type, grouped by label condition\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2b90a0d20100a07be2cef65526c35838",
          "grade": true,
          "grade_id": "cell-385b95f25a862720",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qs2kJn9R_FsK"
      },
      "source": [
        "temp_higher,eda_higher = signals_boxplot(chest_data_no_outliers)\n",
        "assert type(temp_higher)== bool\n",
        "assert type(eda_higher)== bool\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "970adb0fcc7e2fa28a552dc3221a5ff6",
          "grade": false,
          "grade_id": "cell-5e3b2c6585dfbfc0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BS_pe_7C_FsL"
      },
      "source": [
        "### Question 10\n",
        "For the signals 'EDA','TEMP' and 'RESPIRATION', let's use an ANOVA rather than rely on visual analysis to determine if the difference between the mean signal values for the groups is statistically significant at a level of alpha=0.05.\n",
        "\n",
        "Complete the below function `anova_signals()` which takes as input the dataframe `chest_data_no_outliers` and a list of signals `signals` to evaluate.  The function should perform an ANOVA analysis on the signals in the input list `signals`.  Your function should then return a **list** containing the p-values (as floats) of the ANOVA analysis for each of the signals in `signals`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ac7ed87c288177abebb30898ab8e00cf",
          "grade": false,
          "grade_id": "cell-9b13b7889f74bf6d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "xi9a1ITR_FsL"
      },
      "source": [
        "def anova_signals(df,signals):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "42332f488538dba38154fc73469522b4",
          "grade": true,
          "grade_id": "cell-29c73e6773ea2c9b",
          "locked": true,
          "points": 15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ODpJOkRD_FsM"
      },
      "source": [
        "# Test cell for anova_signals()\n",
        "signals = ['EDA','TEMP','RESPIRATION']\n",
        "pvals = anova_signals(chest_data_no_outliers,signals)\n",
        "assert len(pvals) == len(signals)\n",
        "print('Your function calculated the following p values:')\n",
        "print(pvals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c5998eb35b66f4c5954f7cc06c6dc884",
          "grade": false,
          "grade_id": "cell-a6e61283b0d32dc6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "sPRBZZYo_FsM"
      },
      "source": [
        "In addition to our boxplots and statistical tests of differences in mean values, it is a good idea to plot the data again - because sometimes there are other indicators we might look for in the data beyond a difference in means between groups (e.g. one group might have a much higher variance than the others, or there might be an increasing/decreasing trend in values of one group not observed in the others.  Run the below cell which plots scatterplots of the values for 'TEMP', 'EDA' and 'RESPIRATION' colored based on mood.  Take note of differences you observe in the variance or trend of the points occuring during the 'Stressed' state relative to the other mood states.  You may find better indicators here of mood than our previous analyses!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d092804ff50ff3993c5a556540a32c18",
          "grade": false,
          "grade_id": "cell-525dd51a4dfaaae4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "NRWd6Hf4_FsN"
      },
      "source": [
        "fig,ax = plt.subplots(3,1,figsize=(10,10))\n",
        "for i,sig in enumerate(['TEMP','EDA','RESPIRATION']):\n",
        "    axis=ax[i]\n",
        "    for label in chest_data_no_outliers['label'].unique(): # Collect datapoints for each label group and plot on same plot\n",
        "        group = chest_data_no_outliers[chest_data_no_outliers['label']==label]\n",
        "        axis.scatter(group.index.total_seconds(),group[sig],s=.5,label=label)\n",
        "    axis.set_xlabel('Time')\n",
        "    axis.set_ylabel(sig)\n",
        "plt.legend(markerscale=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}