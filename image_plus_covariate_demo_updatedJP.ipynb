{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/petre001/Demo/blob/main/image_plus_covariate_demo_updatedJP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ca14dc9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-09T19:18:39.521490Z",
          "start_time": "2022-06-09T19:18:39.518293Z"
        },
        "id": "6ca14dc9"
      },
      "outputs": [],
      "source": [
        "# This is a sample notebook that shows the basic premise of how\n",
        "# a model can combine both imaging and covariate features. \n",
        "#\n",
        "# Due to the sample nature, none of the models are trained and a\n",
        "# find prediction cannot be shown and would not be accurate at all. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3f6fbe",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-09T19:18:41.353814Z",
          "start_time": "2022-06-09T19:18:39.528070Z"
        },
        "id": "ae3f6fbe"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Do not use a GPU\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/PresentationDemo "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcOcXZQMDXA7",
        "outputId": "ff1ea415-e6ab-48b5-97f9-13046878d724"
      },
      "id": "EcOcXZQMDXA7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/PresentationDemo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb4826e2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-09T19:18:41.368526Z",
          "start_time": "2022-06-09T19:18:41.356113Z"
        },
        "id": "eb4826e2"
      },
      "outputs": [],
      "source": [
        "# Build simple data generator\n",
        "\n",
        "# Additional patient features\n",
        "\n",
        "covariate_columns = [\n",
        "    'Age',\n",
        "    'Sex_F', \n",
        "    'Sex_M',\n",
        "    'APOE A1_2', \n",
        "    'APOE A1_3', \n",
        "    'APOE A1_4', \n",
        "    'APOE A2_2',\n",
        "    'APOE A2_3', \n",
        "    'APOE A2_4', \n",
        "    'LEFT_HIPPOCAMPUS_VOLUME',\n",
        "    'RIGHT_HIPPOCAMPUS_VOLUME', \n",
        "    'MMSE Total Score',\n",
        "    'ADAS13',\n",
        "    'AD', \n",
        "    'CN', \n",
        "    'EMCI', \n",
        "    'LMCI', \n",
        "    'MCI',\n",
        "    'SMC'\n",
        "]\n",
        "\n",
        "class DataGenerator_Gaussian_Labels(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(\n",
        "        self, \n",
        "        target, \n",
        "        batch_size, \n",
        "        dim,\n",
        "        shuffle\n",
        "    ):\n",
        "        \n",
        "        # Get data dir and subject ids\n",
        "        self.data_dir = Path('ad_image_data')\n",
        "        self.subject_ids = [int(x.split('.npy')[0]) for x in os.listdir(self.data_dir) if '.npy' in x]\n",
        "        \n",
        "        # Get labels and covariates\n",
        "        label_df = pd.read_csv('{}_complete_updated_gaussian.csv'.format(target))\n",
        "        self.covariates = label_df[covariate_columns].T.to_dict('list')\n",
        "        self.labels = label_df['A_GAUSSIAN_CLS'].to_dict()\n",
        "    \n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.subject_ids) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        temp_subject_ids = [self.subject_ids[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(temp_subject_ids)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.subject_ids))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, temp_subject_ids):\n",
        "        # Initialization\n",
        "        X_imgs = np.empty((self.batch_size, *self.dim))\n",
        "        X_covariates = np.empty((self.batch_size, len(covariate_columns)), dtype=float)\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(temp_subject_ids):\n",
        "            img = np.load(self.data_dir / '{:04d}.npy'.format(ID))\n",
        "            \n",
        "            # Store sample\n",
        "            X_imgs[i,] = img\n",
        "            X_covariates[i] = list(self.covariates.values())[0] # Getting a sample not an index\n",
        "\n",
        "            # Store class\n",
        "            y[i] = list(self.labels.values())[0] # Getting a sample not an index\n",
        "\n",
        "        return (X_imgs, X_covariates), y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd56ce5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-09T19:18:41.512162Z",
          "start_time": "2022-06-09T19:18:41.370688Z"
        },
        "id": "bbd56ce5"
      },
      "outputs": [],
      "source": [
        "# Create generator\n",
        "\n",
        "train_gen = DataGenerator_Gaussian_Labels(\n",
        "    target = 'A_train', \n",
        "    batch_size = 1, \n",
        "    dim = [182, 182, 218], \n",
        "    shuffle = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fec7c0a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-09T19:18:41.523802Z",
          "start_time": "2022-06-09T19:18:41.514618Z"
        },
        "id": "0fec7c0a"
      },
      "outputs": [],
      "source": [
        "# Define a model that returns features generated from image\n",
        "\n",
        "def Image_Feature_Generator(width=182, height=182, depth=218, dropout=0.5, image_features=50):\n",
        "    image_input = layers.Input((width, height, depth, 1))\n",
        "\n",
        "    x = layers.Conv3D(filters=8, kernel_size=3, padding=\"same\")(image_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    \n",
        "    x = layers.Conv3D(filters=16, kernel_size=3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=32, kernel_size=3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=128, kernel_size=3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    \n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    \n",
        "    x = layers.Dense(1300, activation='relu')(x)\n",
        "    outputs = layers.Dense(image_features, activation='relu')(x)\n",
        "    \n",
        "    # Define the model.\n",
        "    model = keras.Model(image_input, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40dedb2c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-09T19:18:41.757546Z",
          "start_time": "2022-06-09T19:18:41.525580Z"
        },
        "id": "40dedb2c"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "\n",
        "network = Image_Feature_Generator(\n",
        "    dropout = 0.5, \n",
        "    image_features = 50\n",
        ") \n",
        "network.compile(\n",
        "    optimizer = Adam(learning_rate=3e-4),\n",
        "    loss=tf.keras.losses.binary_crossentropy, \n",
        "    metrics=['binary_accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad9c89b9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-09T19:18:42.175250Z",
          "start_time": "2022-06-09T19:18:41.759218Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad9c89b9",
        "outputId": "ee093f4e-4945-4c12-82a4-33223cb1eeb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
              "array([0.        , 0.        , 0.        , 0.        , 0.01003662,\n",
              "       0.0276091 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.01885588, 0.        , 0.02650532, 0.00330343, 0.        ,\n",
              "       0.03354377, 0.03127959, 0.00225191, 0.03273569, 0.        ,\n",
              "       0.00785021, 0.        , 0.        , 0.0752326 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.00404299, 0.03507901,\n",
              "       0.        , 0.00480154, 0.029341  , 0.0827476 , 0.01331555,\n",
              "       0.        , 0.00118107, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.02157245, 0.0447955 , 0.01733352, 0.01550276,\n",
              "       0.        , 0.        , 0.08776416, 0.05509793, 0.        ])>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# Get sample image features\n",
        "\n",
        "for x, y in train_gen:\n",
        "    x_images, x_covariates = x\n",
        "    \n",
        "    image_features = network(x_images)\n",
        "    \n",
        "    break\n",
        "  \n",
        "image_features = tf.cast(tf.squeeze(image_features), tf.float64)\n",
        "\n",
        "image_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "834e8fdc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-09T19:18:42.180273Z",
          "start_time": "2022-06-09T19:18:42.176782Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "834e8fdc",
        "outputId": "59078e74-29c1-42fa-c0e0-0ed3971b9ff5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(19,), dtype=float64, numpy=\n",
              "array([0.5       , 0.        , 1.        , 0.        , 1.        ,\n",
              "       0.        , 0.        , 0.        , 1.        , 0.48875631,\n",
              "       0.6620776 , 0.91304348, 0.05633803, 0.        , 1.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "# Display the covariate features\n",
        "x_covariates = tf.squeeze(x_covariates)\n",
        "\n",
        "x_covariates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c23d40",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-09T19:18:42.187256Z",
          "start_time": "2022-06-09T19:18:42.182346Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75c23d40",
        "outputId": "141ec626-593b-4799-b851-2a6079df54f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(69,), dtype=float64, numpy=\n",
              "array([0.        , 0.        , 0.        , 0.        , 0.01003662,\n",
              "       0.0276091 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.01885588, 0.        , 0.02650532, 0.00330343, 0.        ,\n",
              "       0.03354377, 0.03127959, 0.00225191, 0.03273569, 0.        ,\n",
              "       0.00785021, 0.        , 0.        , 0.0752326 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.00404299, 0.03507901,\n",
              "       0.        , 0.00480154, 0.029341  , 0.0827476 , 0.01331555,\n",
              "       0.        , 0.00118107, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.02157245, 0.0447955 , 0.01733352, 0.01550276,\n",
              "       0.        , 0.        , 0.08776416, 0.05509793, 0.        ,\n",
              "       0.5       , 0.        , 1.        , 0.        , 1.        ,\n",
              "       0.        , 0.        , 0.        , 1.        , 0.48875631,\n",
              "       0.6620776 , 0.91304348, 0.05633803, 0.        , 1.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "# We can now take those image features and add them to the covariate data\n",
        "\n",
        "image_plus_covariate_input = tf.concat([image_features, x_covariates], axis=0)\n",
        "\n",
        "image_plus_covariate_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13c03f9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-09T19:18:42.413653Z",
          "start_time": "2022-06-09T19:18:42.189422Z"
        },
        "id": "a13c03f9"
      },
      "outputs": [],
      "source": [
        "# Feed all of this data through a simple logistic regression model\n",
        "\n",
        "# Define model\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Predict\n",
        "# pred = classifier.predict(image_plus_covariate_input)\n",
        "\n",
        "# Show prediction\n",
        "# pred"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Copy of image plus covariate demo updated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}